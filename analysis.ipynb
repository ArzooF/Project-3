{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Date  Facebook  Pinterest  Twitter  StumbleUpon  YouTube  Instagram  \\\n",
      "0  2009-04     20.16        0.0     6.86        36.79      0.0        0.0   \n",
      "1  2009-05     24.30        0.0     9.95        33.78      0.0        0.0   \n",
      "2  2009-06     26.48        0.0    10.56        29.65      0.0        0.0   \n",
      "3  2009-07     29.10        0.0    10.35        33.55      0.0        0.0   \n",
      "4  2009-08     34.25        0.0    11.15        29.01      0.0        0.0   \n",
      "\n",
      "   Tumblr  reddit  VKontakte  ...  MySpace  Fark  NowPublic  iWiW  \\\n",
      "0     0.0    8.98        0.0  ...    14.81  0.22       0.04  0.29   \n",
      "1     0.0    7.62        0.0  ...     8.95  0.44       0.05  2.10   \n",
      "2     0.0   12.13        0.0  ...     7.66  0.66       0.05  2.35   \n",
      "3     0.0    9.52        0.0  ...     5.49  0.22       0.03  2.21   \n",
      "4     0.0    9.37        0.0  ...     4.69  0.40       0.08  2.27   \n",
      "\n",
      "   news.ycombinator.com  Delicious  orkut  Odnoklassniki  Vimeo  Other  \n",
      "0                  0.08       0.49   1.75            0.0    0.0   2.83  \n",
      "1                  0.12       0.57   1.77            0.0    0.0   2.72  \n",
      "2                  0.11       0.58   1.46            0.0    0.0   1.93  \n",
      "3                  0.14       0.55   1.24            0.0    0.0   1.84  \n",
      "4                  0.08       0.52   1.27            0.0    0.0   1.90  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "      Date  Facebook  Pinterest  Twitter  StumbleUpon  reddit  Tumblr  \\\n",
      "0  2009-04     12.89        0.0     6.69        42.45    9.83     0.0   \n",
      "1  2009-05     15.88        0.0    10.45        42.55    9.10     0.0   \n",
      "2  2009-06     17.02        0.0    11.25        38.08   14.80     0.0   \n",
      "3  2009-07     19.08        0.0    10.55        43.41   11.64     0.0   \n",
      "4  2009-08     24.45        0.0    11.37        38.84   11.85     0.0   \n",
      "\n",
      "   YouTube  Instagram  LinkedIn  Digg  MySpace  Fark  Google+  NowPublic  \\\n",
      "0      0.0        0.0      0.00  6.02    19.04  0.30      0.0       0.03   \n",
      "1      0.0        0.0      0.27  6.85    11.06  0.65      0.0       0.04   \n",
      "2      0.0        0.0      0.50  5.17     9.46  1.03      0.0       0.05   \n",
      "3      0.0        0.0      0.40  5.05     6.86  0.34      0.0       0.05   \n",
      "4      0.0        0.0      0.45  3.92     5.85  0.64      0.0       0.08   \n",
      "\n",
      "   news.ycombinator.com  Delicious  VKontakte  Vimeo  Other  \n",
      "0                  0.08       0.38        0.0    0.0   2.30  \n",
      "1                  0.12       0.46        0.0    0.0   2.57  \n",
      "2                  0.12       0.47        0.0    0.0   2.06  \n",
      "3                  0.15       0.43        0.0    0.0   2.04  \n",
      "4                  0.09       0.41        0.0    0.0   2.06  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into dataframes\n",
    "df1 = pd.read_csv('/Users/NP/Documents/Project-3/Social Media Pouparity 2009-2023/data/social_media.csv')\n",
    "df2 = pd.read_csv('/Users/NP/Documents/Project-3/Social Media Pouparity 2009-2023/data/social_media-US-monthly-200904-202312.csv')\n",
    "\n",
    "# Print the first few rows of the dataframes\n",
    "print(df1.head())\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#etch Google Trends data for the specified social media platforms using the pytrends library:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/_nrym7x567b9m_tg6knvmbyw0000gn/T/ipykernel_23872/1098276140.py:17: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  social_media_trends_df = social_media_trends_df.resample('M').mean()\n",
      "/var/folders/cy/_nrym7x567b9m_tg6knvmbyw0000gn/T/ipykernel_23872/1098276140.py:32: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  mental_health_trends_df = mental_health_trends_df.resample('M').mean()\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define the keywords to search for\n",
    "social_media_keywords = [\"Facebook\", \"Instagram\", \"TikTok\", \"Twitter\", \"Snapchat\"]\n",
    "\n",
    "# Build the payload\n",
    "pytrends.build_payload(social_media_keywords, cat=0, timeframe='2009-01-01 2023-12-31', geo='', gprop='')\n",
    "\n",
    "# Get interest over time\n",
    "social_media_trends_df = pytrends.interest_over_time()\n",
    "\n",
    "# Resample to end of each month and compute mean\n",
    "social_media_trends_df = social_media_trends_df.resample('M').mean()\n",
    "\n",
    "# Save to CSV\n",
    "social_media_trends_df.to_csv('/Users/NP/Documents/Project-3/Social Media Pouparity 2009-2023/data/google_trends_social_media_data.csv')\n",
    "\n",
    "# Define the keywords to search for\n",
    "mental_health_keywords = [\"mental health\", \"happiness\", \"stress\", \"anxiety\", \"well-being\"]\n",
    "\n",
    "# Build the payload\n",
    "pytrends.build_payload(mental_health_keywords, cat=0, timeframe='2009-01-01 2023-12-31', geo='', gprop='')\n",
    "\n",
    "# Get interest over time\n",
    "mental_health_trends_df = pytrends.interest_over_time()\n",
    "\n",
    "# Resample to end of each month and compute mean\n",
    "mental_health_trends_df = mental_health_trends_df.resample('M').mean()\n",
    "\n",
    "# Save to CSV\n",
    "mental_health_trends_df.to_csv('/Users/NP/Documents/Project-3/Social Media Pouparity 2009-2023/data/google_trends_mental_health_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"Project_3_USDataSet\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Iamnotabody$%8!\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  facebook  printest  twitter  stumbleupon  reddit  tumbler  \\\n",
      "0    2009-04     12.89      0.00     6.69        42.45    9.83     0.00   \n",
      "1    2009-05     15.88      0.00    10.45        42.55    9.10     0.00   \n",
      "2    2009-06     17.02      0.00    11.25        38.08   14.80     0.00   \n",
      "3    2009-07     19.08      0.00    10.55        43.41   11.64     0.00   \n",
      "4    2009-08     24.45      0.00    11.37        38.84   11.85     0.00   \n",
      "..       ...       ...       ...      ...          ...     ...      ...   \n",
      "172  2023-08     49.90     14.69    14.63         0.00    1.66     0.26   \n",
      "173  2023-09     49.56     16.66    14.67         0.01    1.18     0.24   \n",
      "174  2023-10     47.96     20.13    13.81         0.01    0.70     0.25   \n",
      "175  2023-11     41.98     25.66    13.43         0.00    1.45     0.27   \n",
      "176  2023-12     47.74     25.52    11.56         0.00    1.48     0.24   \n",
      "\n",
      "     youtube  instagram  linkedin  digg  myspace  fark  Google+  nowpublic  \\\n",
      "0       0.00       0.00      0.00  6.02    19.04  0.30      0.0       0.03   \n",
      "1       0.00       0.00      0.27  6.85    11.06  0.65      0.0       0.04   \n",
      "2       0.00       0.00      0.50  5.17     9.46  1.03      0.0       0.05   \n",
      "3       0.00       0.00      0.40  5.05     6.86  0.34      0.0       0.05   \n",
      "4       0.00       0.00      0.45  3.92     5.85  0.64      0.0       0.08   \n",
      "..       ...        ...       ...   ...      ...   ...      ...        ...   \n",
      "172     2.29      15.85      0.62  0.00     0.00  0.08      0.0       0.00   \n",
      "173     2.02      14.96      0.61  0.00     0.00  0.05      0.0       0.00   \n",
      "174     2.27      14.04      0.74  0.00     0.00  0.07      0.0       0.00   \n",
      "175     2.28      13.98      0.87  0.00     0.00  0.07      0.0       0.00   \n",
      "176     2.11      10.36      0.88  0.00     0.00  0.09      0.0       0.00   \n",
      "\n",
      "     news.ycombinator.com  delicious  vkontakte  vimeo  other  \n",
      "0                    0.08       0.38       0.00    0.0   2.30  \n",
      "1                    0.12       0.46       0.00    0.0   2.57  \n",
      "2                    0.12       0.47       0.00    0.0   2.06  \n",
      "3                    0.15       0.43       0.00    0.0   2.04  \n",
      "4                    0.09       0.41       0.00    0.0   2.06  \n",
      "..                    ...        ...        ...    ...    ...  \n",
      "172                  0.00       0.00       0.01    0.0   0.00  \n",
      "173                  0.00       0.00       0.03    0.0   0.01  \n",
      "174                  0.00       0.00       0.01    0.0   0.00  \n",
      "175                  0.00       0.00       0.01    0.0   0.00  \n",
      "176                  0.01       0.00       0.01    0.0   0.00  \n",
      "\n",
      "[177 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/_nrym7x567b9m_tg6knvmbyw0000gn/T/ipykernel_23872/1227644039.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Write your SQL query\n",
    "query = \"SELECT * FROM US_social_media_popularity;\"\n",
    "# Execute the query and load the results into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
